{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nimport random","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:30.126045Z","iopub.execute_input":"2021-10-23T07:42:30.126575Z","iopub.status.idle":"2021-10-23T07:42:31.171958Z","shell.execute_reply.started":"2021-10-23T07:42:30.126433Z","shell.execute_reply":"2021-10-23T07:42:31.170931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install pickle5 &> /dev/null\n#import pickle5 as pickle","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:31.173825Z","iopub.execute_input":"2021-10-23T07:42:31.174266Z","iopub.status.idle":"2021-10-23T07:42:31.178918Z","shell.execute_reply.started":"2021-10-23T07:42:31.174185Z","shell.execute_reply":"2021-10-23T07:42:31.17778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/csv-files/train.csv')\ndisplay(train_data.head())","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:31.180745Z","iopub.execute_input":"2021-10-23T07:42:31.181905Z","iopub.status.idle":"2021-10-23T07:42:31.226677Z","shell.execute_reply.started":"2021-10-23T07:42:31.181727Z","shell.execute_reply":"2021-10-23T07:42:31.225713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv('../input/csv-files/test.csv')\ndisplay(test_data.head())","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:31.22949Z","iopub.execute_input":"2021-10-23T07:42:31.229839Z","iopub.status.idle":"2021-10-23T07:42:31.25646Z","shell.execute_reply.started":"2021-10-23T07:42:31.229796Z","shell.execute_reply":"2021-10-23T07:42:31.255464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_path(image_id):\n    \"\"\"adding the main path with the image paths\"\"\"\n    \n    return \"../input/tml-cv-challenge/oxford-102-flowers/oxford-102-flowers/{}\".format(image_id)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:31.257827Z","iopub.execute_input":"2021-10-23T07:42:31.258368Z","iopub.status.idle":"2021-10-23T07:42:31.264084Z","shell.execute_reply.started":"2021-10-23T07:42:31.258321Z","shell.execute_reply":"2021-10-23T07:42:31.262913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['path'] = train_data['image_ids'].apply(get_path)\ntest_data['path'] = test_data['image_ids'].apply(get_path)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:31.266533Z","iopub.execute_input":"2021-10-23T07:42:31.266891Z","iopub.status.idle":"2021-10-23T07:42:31.286733Z","shell.execute_reply.started":"2021-10-23T07:42:31.266826Z","shell.execute_reply":"2021-10-23T07:42:31.285469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Directory","metadata":{}},{"cell_type":"code","source":"import os\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:31.288657Z","iopub.execute_input":"2021-10-23T07:42:31.289017Z","iopub.status.idle":"2021-10-23T07:42:31.298075Z","shell.execute_reply.started":"2021-10-23T07:42:31.288972Z","shell.execute_reply":"2021-10-23T07:42:31.297062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG: #the configuration where all parameters/hyperparameters are stored\n    debug=False\n    apex=False\n    print_freq=100\n    num_workers=4\n    model_name='tf_efficientnet_b3_ns'\n    size=256\n    scheduler='CosineAnnealingWarmRestarts' \n    criterion='CrossEntropyLoss' \n    epochs=20\n    T_0=10 \n    lr=1e-4\n    min_lr=1e-6\n    batch_size=32\n    weight_decay=1e-6\n    gradient_accumulation_steps=1\n    max_grad_norm=1000\n    seed=42\n    target_size = 102\n    target_col = 'target'\n    n_fold=5\n    trn_fold = [0, 1, 2, 3, 4]\n    train=True\n    smoothing=0.05\n    \nif CFG.debug:\n    CFG.epochs = 1\n    train = train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:31.30098Z","iopub.execute_input":"2021-10-23T07:42:31.301982Z","iopub.status.idle":"2021-10-23T07:42:31.312593Z","shell.execute_reply.started":"2021-10-23T07:42:31.301937Z","shell.execute_reply":"2021-10-23T07:42:31.311493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\nimport sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master') #using rossman's timm package\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nimport timm\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\nif CFG.apex:\n    from torch.cuda.amp import autocast, GradScaler\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:31.315045Z","iopub.execute_input":"2021-10-23T07:42:31.315312Z","iopub.status.idle":"2021-10-23T07:42:40.852054Z","shell.execute_reply.started":"2021-10-23T07:42:31.315269Z","shell.execute_reply":"2021-10-23T07:42:40.850851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    \"\"\" function to calculate accuracy\"\"\"\n    \n    return accuracy_score(y_true, y_pred)\n\ndef init_logger(log_file=OUTPUT_DIR+'train.log'):\n    \"\"\"for logging the training steps\"\"\"\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()\n\n\ndef seed_torch(seed = 42):\n    \"\"\"to maintain reproducability\"\"\"\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed = CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:40.857113Z","iopub.execute_input":"2021-10-23T07:42:40.857903Z","iopub.status.idle":"2021-10-23T07:42:40.872271Z","shell.execute_reply.started":"2021-10-23T07:42:40.857827Z","shell.execute_reply":"2021-10-23T07:42:40.871301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV Split","metadata":{}},{"cell_type":"code","source":"# making a 5 fold split\nfolds = train_data.copy()\nFold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\nfor n, (train_index, val_index) in enumerate(Fold.split(folds, folds[CFG.target_col])):\n    folds.loc[val_index, 'fold'] = int(n)\nfolds['fold'] = folds['fold'].astype(int)\nprint(folds.groupby(['fold', CFG.target_col]).size())","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:40.875567Z","iopub.execute_input":"2021-10-23T07:42:40.876291Z","iopub.status.idle":"2021-10-23T07:42:40.90916Z","shell.execute_reply.started":"2021-10-23T07:42:40.876245Z","shell.execute_reply":"2021-10-23T07:42:40.907955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\nclass TrainDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['path'].values\n        self.labels = df[CFG.target_col].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.file_names[idx]\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            image = self.transform(image=image)['image']\n        label = torch.tensor(self.labels[idx]).long()\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:40.911145Z","iopub.execute_input":"2021-10-23T07:42:40.911585Z","iopub.status.idle":"2021-10-23T07:42:40.923613Z","shell.execute_reply.started":"2021-10-23T07:42:40.911527Z","shell.execute_reply":"2021-10-23T07:42:40.922558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = TrainDataset(train_data, transform=None)\n\nfor i in range(1):\n    image, label = train_dataset[i]\n    print(image.shape)\n    plt.imshow(image)\n    plt.title(f'label: {label}')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:40.925675Z","iopub.execute_input":"2021-10-23T07:42:40.926132Z","iopub.status.idle":"2021-10-23T07:42:41.308088Z","shell.execute_reply.started":"2021-10-23T07:42:40.926083Z","shell.execute_reply":"2021-10-23T07:42:41.307051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transforms","metadata":{}},{"cell_type":"code","source":"# all the augmentations are defined here here\n# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    \n    if data == 'train':\n        return A.Compose([\n            A.Resize(CFG.size, CFG.size),\n            A.RandomResizedCrop(CFG.size, CFG.size),\n            A.Transpose(p=0.5),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n\n    elif data == 'valid':\n        return A.Compose([\n            A.Resize(CFG.size, CFG.size),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:41.309431Z","iopub.execute_input":"2021-10-23T07:42:41.311075Z","iopub.status.idle":"2021-10-23T07:42:41.323375Z","shell.execute_reply.started":"2021-10-23T07:42:41.311016Z","shell.execute_reply":"2021-10-23T07:42:41.321939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = TrainDataset(train_data, transform=get_transforms(data='train'))\n\nfor i in range(1):\n    image, label = train_dataset[i]\n    plt.imshow(image[0])\n    plt.title(f'label: {label}')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:41.325486Z","iopub.execute_input":"2021-10-23T07:42:41.325975Z","iopub.status.idle":"2021-10-23T07:42:41.594768Z","shell.execute_reply.started":"2021-10-23T07:42:41.325929Z","shell.execute_reply":"2021-10-23T07:42:41.593794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# MODEL \n# ====================================================\nclass CustomEfficientNet(nn.Module):\n    \"\"\" using the efficientnet arch and modifying the final classification head\"\"\"\n    def __init__(self, model_name=CFG.model_name, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(CFG.model_name, pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, CFG.target_size)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:41.596871Z","iopub.execute_input":"2021-10-23T07:42:41.597546Z","iopub.status.idle":"2021-10-23T07:42:41.606133Z","shell.execute_reply.started":"2021-10-23T07:42:41.597501Z","shell.execute_reply":"2021-10-23T07:42:41.604978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CustomEfficientNet(model_name=CFG.model_name, pretrained=False)\ntrain_dataset = TrainDataset(train_data, transform=get_transforms(data='train'))\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True,\n                          num_workers=4, pin_memory=True, drop_last=True)\n\nfor image, label in train_loader:\n    output = model(image)\n    print(output)\n    break","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:41.607144Z","iopub.execute_input":"2021-10-23T07:42:41.607396Z","iopub.status.idle":"2021-10-23T07:42:49.14758Z","shell.execute_reply.started":"2021-10-23T07:42:41.607367Z","shell.execute_reply":"2021-10-23T07:42:49.146441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper Functions","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Helper functions\n# ====================================================\nclass AverageMeter(object):\n    \"\"\"computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef asMinutes(s):\n    \"\"\" convert to minutes\"\"\"\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    \"\"\"keep a tarck of time\"\"\"\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    \"\"\"the main train function is defined here, gradient clipping is done and final loss average is returned\"\"\"\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to train mode\n    model.train()\n    start = end = time.time()\n    global_step = 0\n    for step, (images, labels) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        y_preds = model(images)\n        loss = criterion(y_preds, labels)\n        # record loss\n        losses.update(loss.item(), batch_size)\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n        if CFG.apex:\n            with amp.scale_loss(loss, optimizer) as scaled_loss:\n                scaled_loss.backward()\n        else:\n            loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n            optimizer.step()\n            optimizer.zero_grad()\n            global_step += 1\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n            print('Epoch: [{0}][{1}/{2}] '\n                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  'Grad: {grad_norm:.4f}  '\n                  #'LR: {lr:.6f}  '\n                  .format(\n                   epoch+1, step, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses,\n                   remain=timeSince(start, float(step+1)/len(train_loader)),\n                   grad_norm=grad_norm,\n                   #lr=scheduler.get_lr()[0],\n                   ))\n    return losses.avg\n\n\ndef valid_fn(valid_loader, model, criterion, device):\n    \"\"\" the validation fucntion that returns the average validation loss and the prediction probability for each class(through softmax)\"\"\"\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to evaluation mode\n    model.eval()\n    preds = []\n    start = end = time.time()\n    for step, (images, labels) in enumerate(valid_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        # compute loss\n        with torch.no_grad():\n            y_preds = model(images)\n        loss = criterion(y_preds, labels)\n        losses.update(loss.item(), batch_size)\n        # record accuracy\n        preds.append(y_preds.softmax(1).to('cpu').numpy())\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n            print('EVAL: [{0}/{1}] '\n                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(\n                   step, len(valid_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses,\n                   remain=timeSince(start, float(step+1)/len(valid_loader)),\n                   ))\n    predictions = np.concatenate(preds)\n    return losses.avg, predictions","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:49.150203Z","iopub.execute_input":"2021-10-23T07:42:49.1508Z","iopub.status.idle":"2021-10-23T07:42:49.181057Z","shell.execute_reply.started":"2021-10-23T07:42:49.150747Z","shell.execute_reply":"2021-10-23T07:42:49.179923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Loop","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Train loop\n# ====================================================\ndef train_loop(folds, fold):\n\n    LOGGER.info(f\"========== fold: {fold} training ==========\")\n\n    # ====================================================\n    # loader\n    # ====================================================\n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n\n    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n\n    train_dataset = TrainDataset(train_folds, \n                                 transform=get_transforms(data='train'))\n    valid_dataset = TrainDataset(valid_folds, \n                                 transform=get_transforms(data='valid'))\n\n    train_loader = DataLoader(train_dataset, \n                              batch_size=CFG.batch_size, \n                              shuffle=True, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, \n                              batch_size=CFG.batch_size, \n                              shuffle=False, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    \n    # ====================================================\n    # scheduler \n    # ====================================================\n    def get_scheduler(optimizer):\n        \"\"\" function that gets the scheduler\"\"\"\n        if CFG.scheduler=='ReduceLROnPlateau':\n            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n        elif CFG.scheduler=='CosineAnnealingLR':\n            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n        return scheduler\n\n    # ====================================================\n    # model & optimizer\n    # ====================================================\n\n    model = CustomEfficientNet(CFG.model_name, pretrained=True)\n    \n    model.to(device) #move to gpu if available\n\n    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n    scheduler = get_scheduler(optimizer)\n\n    # ====================================================\n    # apex\n    # ====================================================\n    if CFG.apex:\n        model, optimizer = amp.initialize(model, optimizer, opt_level='O1', verbosity=0)\n        \n    \n    def get_criterion():\n        \"\"\" get the loss function \"\"\"\n        if CFG.criterion=='CrossEntropyLoss':\n            criterion = nn.CrossEntropyLoss()\n        elif CFG.criterion=='LabelSmoothing':\n            criterion = LabelSmoothingLoss(classes=CFG.target_size, smoothing=CFG.smoothing)\n        return criterion\n\n\n    # ====================================================\n    # loop \n    # ====================================================\n    criterion = get_criterion()\n    LOGGER.info(f'Criterion: {criterion}')\n\n    best_score = 0.\n    best_loss = np.inf\n    \n    for epoch in range(CFG.epochs):\n        \n        start_time = time.time()\n        \n        # train\n        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n\n        # eval\n        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n        valid_labels = valid_folds[CFG.target_col].values\n        \n        if isinstance(scheduler, ReduceLROnPlateau): \n            scheduler.step(avg_val_loss)\n        elif isinstance(scheduler, CosineAnnealingLR):\n            scheduler.step()\n        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n            scheduler.step()\n\n        # scoring\n        score = get_score(valid_labels, preds.argmax(1)) #use the argmax to get the highest index label and calculate accuracy\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - Accuracy: {score}')\n\n        if score > best_score: #if the curr score is better than previous best, save and replace the best score\n            best_score = score\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save({'model': model.state_dict(), \n                        'preds': preds},\n                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth')\n    \n    check_point = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth')\n    valid_folds['preds'] = check_point['preds'].argmax(1)\n\n    return valid_folds","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:49.182902Z","iopub.execute_input":"2021-10-23T07:42:49.18325Z","iopub.status.idle":"2021-10-23T07:42:49.210788Z","shell.execute_reply.started":"2021-10-23T07:42:49.183206Z","shell.execute_reply":"2021-10-23T07:42:49.209363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# main\n# ====================================================\ndef main():\n    def get_result(result_df):\n        preds = result_df['preds'].values\n        labels = result_df[CFG.target_col].values\n        score = get_score(labels, preds)\n        LOGGER.info(f'Score: {score:<.5f}')\n    \n    if CFG.train: #also making an out of fold dataframe for every prediction we make\n        # train \n        oof_df = pd.DataFrame()\n        for fold in range(CFG.n_fold):\n            if fold in CFG.trn_fold:\n                _oof_df = train_loop(folds, fold)\n                oof_df = pd.concat([oof_df, _oof_df])\n                LOGGER.info(f\"========== fold: {fold} result ==========\")\n                get_result(_oof_df)\n        # CV result\n        LOGGER.info(f\"========== CV ==========\")\n        get_result(oof_df)\n        # save result\n        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:49.214329Z","iopub.execute_input":"2021-10-23T07:42:49.214916Z","iopub.status.idle":"2021-10-23T07:42:49.227059Z","shell.execute_reply.started":"2021-10-23T07:42:49.214851Z","shell.execute_reply":"2021-10-23T07:42:49.225603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__': #The entry point for the program to run\n    main()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T07:42:49.228818Z","iopub.execute_input":"2021-10-23T07:42:49.229387Z","iopub.status.idle":"2021-10-23T08:26:02.549151Z","shell.execute_reply.started":"2021-10-23T07:42:49.2293Z","shell.execute_reply":"2021-10-23T08:26:02.547976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_df = pd.read_csv('./oof_df.csv')\noof_df","metadata":{"execution":{"iopub.status.busy":"2021-10-23T08:29:35.804643Z","iopub.execute_input":"2021-10-23T08:29:35.804978Z","iopub.status.idle":"2021-10-23T08:29:35.835248Z","shell.execute_reply.started":"2021-10-23T08:29:35.804943Z","shell.execute_reply":"2021-10-23T08:29:35.834235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}